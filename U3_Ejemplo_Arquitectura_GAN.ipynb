{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNctkNX7HAFyplDGqum0TZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcmachicao/MachineLearningAvanzado_UC_2024/blob/main/U3_Ejemplo_Arquitectura_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "Aqw7TEbHtDW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la arquitectura del generador\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, image_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.image_shape = image_shape\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Tanh()  # Capa de salida con función de activación tanh para generar imágenes entre -1 y 1\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *self.image_shape)  # Remodelar la salida para que tenga la forma de una imagen\n",
        "        return img"
      ],
      "metadata": {
        "id": "SCykxwiXtDMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la arquitectura del discriminador\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.image_shape = image_shape\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()  # Capa de salida con función de activación sigmoide para clasificar entre real o falso\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)  # Aplanar la imagen para pasarla al discriminador\n",
        "        validity = self.model(img_flat)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "zpw7cjj6tPV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros\n",
        "latent_dim = 100\n",
        "image_shape = (1, 28, 28)  # Tamaño de las imágenes MNIST\n",
        "\n",
        "# Inicializar generador y discriminador\n",
        "generator = Generator(latent_dim, image_shape)\n",
        "discriminator = Discriminator(image_shape)\n",
        "\n",
        "# Definir la función de pérdida y los optimizadores\n",
        "adversarial_loss = nn.BCELoss()  # Pérdida adversarial utilizando la entropía cruzada binaria\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Configurar los datos de MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "dataset = datasets.MNIST(root='mnist_data/', train=True, transform=transform, download=True)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "r5hepjNqtSwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjqMdU-JtBbU"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del GAN\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        # Entrenar al discriminador\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Configurar las etiquetas para imágenes reales y falsas\n",
        "        real_labels = torch.ones(imgs.size(0), 1)\n",
        "        fake_labels = torch.zeros(imgs.size(0), 1)\n",
        "\n",
        "        # Generar ruido aleatorio\n",
        "        z = torch.randn(imgs.size(0), latent_dim)\n",
        "\n",
        "        # Generar imágenes falsas\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Evaluar imágenes reales y falsas con el discriminador\n",
        "        real_loss = adversarial_loss(discriminator(imgs), real_labels)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake_labels)\n",
        "\n",
        "        # Calcular la pérdida total del discriminador\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # Retropropagación y optimización\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Entrenar al generador\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Evaluar imágenes generadas por el generador con el discriminador\n",
        "        validity = discriminator(gen_imgs)\n",
        "        g_loss = adversarial_loss(validity, real_labels)\n",
        "\n",
        "        # Retropropagación y optimización\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Imprimir progreso del entrenamiento\n",
        "        print(\n",
        "            f\"Epoch [{epoch}/{num_epochs}], Batch [{i}/{len(dataloader)}], \"\n",
        "            f\"Loss D: {d_loss.item():.4f}, Loss G: {g_loss.item():.4f}\"\n",
        "        )\n",
        "\n",
        "        # Guardar imágenes generadas durante el entrenamiento\n",
        "        if i % 400 == 0:\n",
        "            torchvision.utils.save_image(gen_imgs.data[:25], f\"gan_images/{epoch}_{i}.png\", nrow=5, normalize=True)"
      ]
    }
  ]
}