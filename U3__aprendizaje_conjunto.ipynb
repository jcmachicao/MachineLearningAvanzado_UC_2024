{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcmachicao/MachineLearningAvanzado_UC_2025/blob/main/U3__aprendizaje_conjunto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo de aprendizaje conjunto"
      ],
      "metadata": {
        "id": "9CxBFBJcNlzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El aprendizaje conjunto (joint learning) es una técnica en deep learning donde se entrenan múltiples tareas o componentes de una red neuronal simultáneamente, compartiendo información y parámetros entre ellos. En el aprendizaje conjunto, la red neuronal aprende a optimizar múltiples objetivos al mismo tiempo, permitiendo que las diferentes partes del modelo se beneficien mutuamente durante el entrenamiento.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "1. La red puede estar aprendiendo a reconocer objetos en imágenes mientras simultáneamente aprende a segmentar esas mismas imágenes.\n",
        "\n",
        "2. Los parámetros y representaciones aprendidas en las capas iniciales se comparten entre las diferentes tareas, lo que permite una transferencia de conocimiento implícita.\n",
        "\n",
        "3. La función de pérdida total generalmente es una combinación ponderada de las pérdidas individuales de cada tarea.\n",
        "\n",
        "Las ventajas principales del aprendizaje conjunto incluyen:\n",
        "\n",
        "- Mejor generalización, ya que el modelo aprende representaciones más robustas al tener que satisfacer múltiples objetivos\n",
        "- Mayor eficiencia computacional comparado con entrenar modelos separados\n",
        "- Capacidad de capturar relaciones y dependencias entre diferentes tareas\n",
        "\n",
        "Un ejemplo práctico sería una red neuronal que procesa imágenes médicas y simultáneamente:\n",
        "- Clasifica si hay una patología presente\n",
        "- Segmenta la región afectada\n",
        "- Predice la severidad de la condición\n",
        "\n",
        "¿Te gustaría que profundicemos en algún aspecto específico del aprendizaje conjunto?"
      ],
      "metadata": {
        "id": "LA2auPmUWWRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ],
      "metadata": {
        "id": "WNfUPffdTqil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "id": "6T2cCthjUgFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "-hQdDjvyNrsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de ejemplo\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self):\n",
        "\n",
        "        # Textos codificados (usando embeddings ficticios para simplificar)\n",
        "        self.data = torch.tensor([\n",
        "            [1, 0, 0, 0, 0],  # \"E=mc² es la base de la física moderna\" -> Ciencia, Formal\n",
        "            [0, 1, 0, 0, 0],  # \"La gravedad es bien testaruda cuando actúa\" -> Ciencia, Informal\n",
        "            [0, 0, 1, 0, 0],  # \"Los museos son escenciales para la cultura\" -> Arte, Formal\n",
        "            [0, 0, 0, 1, 0],  # \"Qué locura fue el partido de tenis de ayer\" -> Deportes, Informal\n",
        "            [0, 0, 0, 0, 1],  # \"Este pintor tiene obras loquísimas\" -> Arte, Informal\n",
        "        ], dtype=torch.float32)\n",
        "\n",
        "        self.labels_tema = torch.tensor([0, 0, 1, 2, 1])  # Ciencia=0, Arte=1, Deportes=2\n",
        "        self.labels_estilo = torch.tensor([0, 1, 0, 1, 1])  # Formal=0, Informal=1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels_tema[idx], self.labels_estilo[idx]"
      ],
      "metadata": {
        "id": "443uUTZXNrpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo multitarea\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, input_size, tema_classes, estilo_classes):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        # Capas compartidas\n",
        "        self.shared = nn.Linear(input_size, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Rama para tema\n",
        "        self.tema_branch = nn.Linear(16, tema_classes)\n",
        "\n",
        "        # Rama para estilo\n",
        "        self.estilo_branch = nn.Linear(16, estilo_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pasar por la parte compartida\n",
        "        shared_output = self.relu(self.shared(x))\n",
        "\n",
        "        # Salidas de las ramas específicas\n",
        "        tema_output = self.tema_branch(shared_output)\n",
        "        estilo_output = self.estilo_branch(shared_output)\n",
        "\n",
        "        return tema_output, estilo_output"
      ],
      "metadata": {
        "id": "zYXZBhO9Nrme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYtJjr_yNh-i",
        "outputId": "cd75c9d6-65f8-4bf5-8266-69f7cadd94d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.TextDataset object at 0x7a2f3de0a9b0>\n"
          ]
        }
      ],
      "source": [
        "# Inicialización del modelo, datos y entrenamiento\n",
        "dataset = TextDataset()\n",
        "print(dataset)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "input_size = 5  # Tamaño del embedding ficticio\n",
        "tema_classes = 3  # Ciencia, Arte, Deportes\n",
        "estilo_classes = 2  # Formal, Informal\n",
        "\n",
        "model = MultiTaskModel(input_size, tema_classes, estilo_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    for inputs, tema_labels, estilo_labels in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        tema_output, estilo_output = model(inputs)\n",
        "\n",
        "        # Cálculo de las pérdidas\n",
        "        loss_tema = criterion(tema_output, tema_labels)\n",
        "        loss_estilo = criterion(estilo_output, estilo_labels)\n",
        "        total_loss_batch = loss_tema + loss_estilo\n",
        "\n",
        "        # Backpropagation y optimización\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += total_loss_batch.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If7Jg04AN9li",
        "outputId": "e70b893c-a135-4c66-d283-c0cd14568494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 9.1526\n",
            "Epoch 2/20, Loss: 8.5489\n",
            "Epoch 3/20, Loss: 8.0630\n",
            "Epoch 4/20, Loss: 7.6251\n",
            "Epoch 5/20, Loss: 7.2268\n",
            "Epoch 6/20, Loss: 6.7408\n",
            "Epoch 7/20, Loss: 6.3148\n",
            "Epoch 8/20, Loss: 5.8031\n",
            "Epoch 9/20, Loss: 5.3055\n",
            "Epoch 10/20, Loss: 4.7657\n",
            "Epoch 11/20, Loss: 4.2077\n",
            "Epoch 12/20, Loss: 3.6940\n",
            "Epoch 13/20, Loss: 3.2271\n",
            "Epoch 14/20, Loss: 2.7710\n",
            "Epoch 15/20, Loss: 2.3482\n",
            "Epoch 16/20, Loss: 2.0301\n",
            "Epoch 17/20, Loss: 1.7207\n",
            "Epoch 18/20, Loss: 1.4657\n",
            "Epoch 19/20, Loss: 1.2413\n",
            "Epoch 20/20, Loss: 1.0519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba del modelo\n",
        "test_input = torch.tensor([[1, 0, 0, 0, 0]], dtype=torch.float32)  # \"E=mc²...\"\n",
        "tema_pred, estilo_pred = model(test_input)\n",
        "print(f\"Tema predicho: {torch.argmax(tema_pred, dim=1).item()}\")\n",
        "print(f\"Estilo predicho: {torch.argmax(estilo_pred, dim=1).item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LT2QQ_N9eY",
        "outputId": "d77528ae-dc95-4bc7-dee3-57acb28542f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tema predicho: 0\n",
            "Estilo predicho: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulOM_r3hN9QU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}